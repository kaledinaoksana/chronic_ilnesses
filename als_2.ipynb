{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME=\"df_condition.csv\"\n",
    "\n",
    "min_num_of_records = 5\n",
    "min_trackable_name_count = 50\n",
    "min_num_of_dates = 2\n",
    "\n",
    "NUM_TOP_K = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TestData:\n",
    "    @staticmethod\n",
    "    def check_user_existence(df, user_id):\n",
    "        \"\"\"\n",
    "        Check if a user with the given user_id exists in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): The DataFrame to check.\n",
    "            user_id (str): The user_id to check for.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the user exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return user_id in df['user_id'].values\n",
    "\n",
    "    @staticmethod\n",
    "    def test_user_concatenation(df_clean, test_df, train_df, test_id, min_num_of_records=1):\n",
    "        \"\"\"\n",
    "        Test the concatenation of train and test dataframes for a user.\n",
    "\n",
    "        Args:\n",
    "            df_clean (DataFrame): The clean DataFrame.\n",
    "            test_df (DataFrame): The test DataFrame.\n",
    "            train_df (DataFrame): The train DataFrame.\n",
    "            test_id (str): The user_id to test.\n",
    "            min_num_of_records (int): The minimum number of records for a valid user.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the concatenation is correct, False otherwise.\n",
    "        \"\"\"\n",
    "        def df_id(df, test_id):\n",
    "            return df.loc[df[\"user_id\"]==test_id]\n",
    "\n",
    "        user = df_id(df_clean, test_id)\n",
    "        user_test = df_id(test_df, test_id)\n",
    "        user_train= df_id(train_df, test_id)\n",
    "\n",
    "        concatenated_user = pd.concat([user_train, user_test]).sort_index()\n",
    "        return user.sort_index().equals(concatenated_user) and len(user) > min_num_of_records\n",
    "    \n",
    "    @staticmethod\n",
    "    def run_tests(df_clean, test_df, train_df, min_num_of_records=1):\n",
    "        \"\"\"\n",
    "        Run all tests.\n",
    "\n",
    "        Args:\n",
    "            df_clean (DataFrame): The clean DataFrame.\n",
    "            test_df (DataFrame): The test DataFrame.\n",
    "            train_df (DataFrame): The train DataFrame.\n",
    "            min_num_of_records (int): The minimum number of records for a valid user.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if all tests pass, False otherwise.\n",
    "        \"\"\"\n",
    "        test_ids=['QEVuQwEA++z6GMJgxyjYYw0jFdXeDw==', # user with a lot of rows\n",
    "                'QEVuQwEAUGIfNYeSSYSHAiACdW4/EA==', # user with a 1 row\n",
    "                'QEVuQwEAmoJdC6S79c4qmNNWxXJtFA==', # user with a 2 row\n",
    "                'QEVuQwEAsBPVHou+Hpfq1GeehpjG6Q==', # user NaN\n",
    "                'QEVuQwEAO18wayHaoaXcyWjKktyzYA=='] # usual user\n",
    "\n",
    "        # Проверка существования пользователей\n",
    "        for test_id in test_ids:\n",
    "            assert TestData.check_user_existence(df_clean, test_id)\n",
    "\n",
    "        # Тест конкатенации пользовательских данных\n",
    "        assert TestData.test_user_concatenation(df_clean, test_df, train_df, test_ids[0], min_num_of_records)\n",
    "        assert not TestData.test_user_concatenation(df_clean, test_df, train_df, 'nonexistent_user_id', min_num_of_records)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSpreparation:\n",
    "    # preparation to als\n",
    "    def some_ids_preparation_to_als(user_item_matrix):\n",
    "\n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "        \n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "        \n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "        \n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "        \n",
    "        return itemid_to_id, userid_to_id, id_to_itemid, id_to_userid\n",
    "    \n",
    "    # als_prep = ALSpreparation()\n",
    "    # itemid_to_id, userid_to_id, id_to_itemid, id_to_userid = als_prep.some_ids_preparation_to_als(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создание экземпляра класса TestData\n",
    "# test_data = TestData()\n",
    "\n",
    "# # Запуск всех тестов\n",
    "# assert test_data.run_tests(df_clean, test_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# плотность матрицы\n",
    "def matrix_density(df):\n",
    "    return df.sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
    "\n",
    "# поиск\n",
    "def find_row_by_user(dff, user, by=\"user_id\"):\n",
    "    return dff[(dff[by] == user)]\n",
    "\n",
    "def find_row_by_user_and_condition(dff, user, cond, by=\"user_id\"):\n",
    "    return dff[(dff[by] == user) & (dff[\"trackable_name\"] == cond)]\n",
    "\n",
    "def find_rows_by_column_value(df, col, value):\n",
    "    return df[(df[col] == value)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "**raw_data** - сырые данные \n",
    "\n",
    "**df** - очищенные данные\n",
    "\n",
    "**mapping_matrix_id** - таблица соответствия user_id и numeric_user_id\n",
    "\n",
    "**mapping_matrix_trackable** - таблица соответствия trackable_name и numeric_trackable_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_num_of_records = 10\n",
    "min_trackable_name_count = 50\n",
    "min_num_of_dates = 6\n",
    "\n",
    "import TimeSeriesProcessor\n",
    "proc = TimeSeriesProcessor.TimeSeriesDataProcessor()\n",
    "\n",
    "def clean_df(df):\n",
    "    \n",
    "    # proc.list_methods()\n",
    "    \n",
    "    # Удаляем, где у юзеров нет age/sex/country (данных достаточно)\n",
    "    df = df.dropna(subset=['age', 'sex','country'])\n",
    "    # Подсчитываем количество встречаемости trackable_name\n",
    "    df_count_trackable_name = proc.calculate_counttable_by_columnname(df,\"trackable_name\").sort_values(by='count', ascending=False)\n",
    "    # Выбираем записи, где количество встречаемости trackable_name > min_trackable_name_count\n",
    "    df_clean = proc.delete_rows_with_higher_count(df=df, df_count=df_count_trackable_name, min_count=min_trackable_name_count, col='trackable_name')\n",
    "    # Удаляем ненужные колонки\n",
    "    df_clean = proc.drop_columns_by_columnsnames(df_clean, ['count', 'trackable_type'])\n",
    "    # Подсчитываем количество записей на каждого юзера и фильтруем count_of_records >= min_num_of_records\n",
    "    filtered_users_with_counts = proc.filter_by_min_records(df_clean, min_num_of_records)\n",
    "    # Оставляем в df_clean только отфильтрованные user_id\n",
    "    df_clean = df_clean[df_clean['user_id'].isin(filtered_users_with_counts[\"user_id\"])]\n",
    "    # Фильтруем, что у пользователя количество дат записей >= min_num_of_dates\n",
    "    df_clean = proc.filter_by_min_number_of_dates(df_clean, min_num_of_dates)\n",
    "\n",
    "    # Create mapping matrices for 'user_id' and 'trackable_name'\n",
    "    mapping_matrix_id, df_cleaned = proc.create_mapping_matrix(df_clean, 'user_id')\n",
    "    mapping_matrix_trackable, df_cleaned = proc.create_mapping_matrix(df_clean, 'trackable_name')\n",
    "   \n",
    "    df_c = proc.drop_columns_by_columnsnames(df_cleaned,['user_id','trackable_name'])\n",
    "    \n",
    "    new_order = ['numeric_user_id', 'age', 'sex','country','checkin_date','numeric_trackable_name','trackable_value']\n",
    "    df_c = df_c.reindex(columns=new_order)\n",
    "\n",
    "    return df_c, mapping_matrix_id, mapping_matrix_trackable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of saved rows = 74.07% or 823271 rows\n"
     ]
    }
   ],
   "source": [
    "raw_data = proc.load_csv(FILENAME)\n",
    "df, mapping_matrix_id, mapping_matrix_trackable = clean_df(raw_data.copy())\n",
    "\n",
    "print(\"Percent of saved rows = {percent:.2f}% or {num:d} rows\".format(percent=df.shape[0]*100/raw_data.shape[0], num=df.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
